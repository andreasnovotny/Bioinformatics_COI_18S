---
title: "Inspect prepare and combine datasets"
---

```{r}
library(lubridate)
library(plotly)
library(tidyverse)
library(readxl)
library(googledrive)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

# COI #################

## Load and merge data tables:

### ASV table:

Read in ASV table, and modify names:
```{r}
ASV_COI_tmp <-
  read.delim("ProcessedData/COI_Andreas/ASV/sequence_table.merged.txt",
             sep = " ") %>% 
  rename_with(~gsub(., pattern = "\\.", replacement = "_")) %>%
  rownames_to_column("ASV") %>% 
  select(!Sequence) %>% 
  replace(is.na(.), 0) %>% 
  mutate(ASV = paste("ASV", ASV, sep = ""))

ASV_COI_tmp
```

### Sample metadata:

Read in metadata:

```{r}
Samptab_COI_tmp <-
  read_excel("ProcessedData/metadata_files/Library_metadata_all.xlsx", 
             sheet = "COI", col_types = c("text",
        "text", "date", "text", "text", "text", 
        "text", "date", "date", "numeric", 
        "text", "date", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "date", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "numeric", "numeric", "text"))
Samptab_COI_tmp


```

Check what original samples are missing from the ASV table:

```{r}
SamplesNotInASV <-
  Samptab_COI_tmp %>%
  filter(Library_ID %!in% colnames(ASV_COI_tmp)) %>% 
  pull(Library_ID)

SamplesNotInASV
```

**Investigate why samples are not present by back-tracing intermediates:**

-FW22XN01_COI removed in filtering step (Blank, no reads left)\
-Blank1_COI removed in filtering step (Blank, no reads left)\
-QMIC3678_COI low read abundance before and after filter and trim\
-QMIC3601_COI low read abundance before and after filter and trim\
-QMIC2991_COI low read abundance before and after filter and trim\
-QMIC2867_COI low read abundance before and after filter and trim

These samples exist in sequence data but not metadata:

```{r}
samplesNotInMetadata <- 
  colnames(ASV_COI_tmp) %>% 
  tibble() %>% 
  filter(. %!in% pull(Samptab_COI_tmp, Library_ID)) %>% 
  pull

samplesNotInMetadata

```

Undetermined samples are produced in the bioinformatic pipeline. It is sequences that due to errors canot be assigned any sample.\
the presences of undermined samples are ok. If othr samples show up here it is due to errors. Check.


### Taxonomy Table
```{r}
Taxtab_COI_tmp <- read.delim("ProcessedData/COI_Andreas/COI_taxonomy/taxonomy_table.CO1.iterative_blast.LCA+best_hit.txt") %>% 
  rename_with(~gsub(., pattern = "X.", replacement = "")) %>% 
  rename(ASV = Query)
Taxtab_COI_tmp
```


### Merge and save datasets

```{r}
# Merge data components to one big dataframe

COI_df <- 
  Taxtab_COI_tmp %>%
  full_join(ASV_COI_tmp, by = "ASV") %>%
  pivot_longer(!1:12, names_to = "Library_ID", values_to = "Abundance") %>%
  full_join(Samptab_COI_tmp, by = "Library_ID")

COI_df
# This object is very large. Do not push to git remote.
# Rather save the individual components or upload to cloud.

saveRDS(Taxtab_COI_tmp, "Data_export/Taxtab_COI.rds")
saveRDS(ASV_COI_tmp, "Data_export/ASV_COI.rds")
saveRDS(Samptab_COI_tmp, "Data_export/Samptab_COI.rds")

```



## Plot Sequencing Depth

```{r}
depth <-
  COI_df %>% 
  group_by(Library_ID) %>% 
  summarize(Abundance=sum(Abundance))
depth


depth %>% 
  ggplot() +
  geom_bar(aes(Library_ID, Abundance), stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

COI_df %>% 
  filter(Library_ID %in% c("Blank_COI", "Blank_COI_2018", "FW22XN04_COI", "FW22XN05_COI"),
         Abundance > 0)
```


## PLot Negative controls

```{r}
nullplot <- 
  COI_df %>% 
  filter(is.na(Project_name)) %>% 
  ggplot() +
  geom_bar(aes(Library_ID, Abundance, fill=phylum), stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

plotly::ggplotly(nullplot)
```

# 18S #################

## Load and merge data tables:

### ASV and taxtab

```{r}
read_18S <- function(dir = "18S_QPKbulk_2017") {
  
  ASV_18S_tmp <-
    read.delim(paste("ProcessedData/18S_Andreas/",dir,"/sequence_table.merged.txt", sep = "")) %>% 
    column_to_rownames("row_names") %>% 
    t() %>%
    as.data.frame() %>% 
    rownames_to_column("Sequence")

  Taxtab_18S_tmp <- readRDS(paste("ProcessedData/18S_Andreas/",dir,"/tax_tab_18S_pr2.RDS", sep = ""))$tax %>%
    as.data.frame() %>% 
    rownames_to_column("Sequence")

  ASV_Tax_18S_tmp <- Taxtab_18S_tmp %>% 
    left_join(ASV_18S_tmp, by = "Sequence") %>% 
    select(!Sequence)
}

shrink <- function(ASV_table) {
  
  unite(ASV_table, Taxa, 1:8, sep = "&") %>% 
  pivot_longer(2:length(.), names_to = "Library_ID", values_to = "Abundance") %>% 
  group_by(Library_ID, Taxa) %>% 
  summarise(Abundance = sum(Abundance)) %>% 
  pivot_wider(names_from = "Library_ID", values_from = "Abundance")
  
}


ASV_18S_QPKbulk2017 <- read_18S("18S_QPKbulk_2017")
ASV_18S_QU39_1 <- read_18S("18S_QU39_1")
ASV_18S_QU39_2 <- read_18S("18S_QU39_2")
ASV_18S_QU39_3 <- read_18S("18S_QU39_3")
ASV_18S_QU39_4 <- read_18S("18S_QU39_4")
ASV_18S_QU39_5 <- read_18S("18S_QU39_5")

ASV_18S_all <- shrink(ASV_18S_QPKbulk2017) %>% 
  full_join(shrink(ASV_18S_QU39_1), by = "Taxa") %>% 
  full_join(shrink(ASV_18S_QU39_2), by = "Taxa") %>%
  full_join(shrink(ASV_18S_QU39_3), by = "Taxa") %>%
  full_join(shrink(ASV_18S_QU39_4), by = "Taxa") %>%
  full_join(shrink(ASV_18S_QU39_5), by = "Taxa") %>% 
  separate(Taxa, into = c("Kingdom", "Supergroup", "Divition", "Class",
                          "Order","Family", "Genus", "Species"),
           sep = "&")

ASV_18S_all %>% 
  saveRDS(file = "Data_export/ASV_Taxtab_18S.rds")

  
ASV_18S_all


```


### Sample data
All 18S sample data:

```{r}

qu39DNA_metadata <- read_excel(
   "ProcessedData/metadata_files/qu39DNA_metadata.xlsx", 
   col_types = c("date", "text", "numeric",
                 "text", "date", "date", "text", "numeric",
                 "text", "date", "text", "numeric",
                 "numeric", "numeric", "text", "text")) %>% 
  transmute(
    Library_ID = `Hakai ID`,
    Hakai_ID = `Hakai ID`,
    Sample_date = Date,
    Project_name = "QU39",
    Site_ID = `Site ID`,
    Line_out_depth = `Line Out Depth`,
    Sample_type = `Sample Type`,
    Time_collected = Collected,
    Time_preserved = Preserved,
    Sample_volume_ml = `Volume (ml)`,
    Sample_technician = `Lab Technician`,
    DNA_extraction_date = `DNA Extraction Date`,
    DNA_extraction_method = "Phenol-Clorophorm",
    DNA_volume_ul = `DNA Volume with TE Wash (ul)`,
    Qubit_DNA_Concentration_ngml = `Qubit DNA Concentration (ng/ml)`,
    Stock_DNA_Conentration_ngul =`Stock DNA Conentration (ng/ul)`,
    Extraction_staff = `Extraction Staff`,
    MiSeq_library = "Home18S",
    Library_staff = "Catherina Rodriguez"
  ) #%>% 
  #filter(Sample_type == "DNA") %>% 
  #filter(year(Sample_date)<2018)

qu39DNA_metadata


Library_metadata_Andreas <- read_excel("ProcessedData/metadata_files/Library_metadata_all.xlsx", 
     sheet = "18S", col_types = c("text", 
         "text", "date", "text", "text", "numeric", 
         "text", "date", "date", "numeric", 
         "text", "date", "text", "numeric", 
         "numeric", "numeric", "numeric", 
         "text", "text", "text", "text", "date", 
         "text", "text", "numeric", "numeric", 
         "text", "text", "text", "text", "numeric", 
         "numeric", "numeric"))

Library_metadata_Andreas


Samptab_18S_all <- bind_rows(Library_metadata_Andreas, qu39DNA_metadata)

Samptab_18S_all %>% 
    saveRDS(file = "Data_export/Samptab_18S.rds")

```

### Merge and check:

```{r}
all_18S <- ASV_18S_all %>% 
  pivot_longer(9:length(.), names_to = "Library_ID", values_to = "Abundance") %>% 
  left_join(Samptab_18S_all, by = c("Library_ID"))

all_18S
```



Check what original samples are missing from the ASV table:

```{r}
SamplesNotInASV <-
  Samptab_18S_all %>%
  filter(year(Sample_date) %in% 2015:2018) %>% 
  filter(Library_ID %!in% colnames(ASV_18S_all)) %>% 
  pull(Library_ID)

SamplesNotInASV


Samptab_18S_all

ASV_18S_all

```

**Investigate why samples are not present by back-tracing intermediates:**

These samples exist in sequence data but not metadata:

```{r}
samplesNotInMetadata <- 
  colnames(ASV_18S_all) %>% 
  tibble() %>% 
  filter(. %!in% pull(Samptab_18S_all, Library_ID)) %>% 
  pull

samplesNotInMetadata
```





# 12S ##################

## Load and merge data tables
### ASV table:

Read in ASV table, and modify names:
```{r}
ASV_12S_tmp <-
  read.delim("ProcessedData/12S_Andreas/ASV/sequence_table.merged.txt",
             sep = " ") %>% 
  rename_with(~gsub(., pattern = "\\.", replacement = "_")) %>%
  rownames_to_column("ASV") %>% 
  select(!Sequence) %>% 
  replace(is.na(.), 0) %>% 
  mutate(ASV = paste("ASV", ASV, sep = ""))

ASV_12S_tmp
```

### Sample metadata:

Read in metadata:

```{r}
Samptab_12S_tmp <- read_excel("ProcessedData/metadata_files/Library_metadata_all.xlsx", 
    sheet = "12S", col_types = c("text", 
        "text", "date", "text", "text", "text", 
        "text", "date", "date", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "numeric", "text", "text", "numeric", 
        "numeric", "text", "text", "text", 
        "text", "numeric", "numeric", "text"))
Samptab_12S_tmp
```

Check what original samples are missing from the ASV table:

```{r}
SamplesNotInASV <-
  Samptab_12S_tmp %>%
  filter(Library_ID %!in% colnames(ASV_12S_tmp)) %>% 
  pull(Library_ID)

SamplesNotInASV

```

### Taxonomy Table

```{r}
  Taxtab_12S_tmp <- read.delim( "ProcessedData/12S_Andreas/Taxonomy/taxonomy_table.12S.NCBI_NT.96sim.LCA+besthit.txt") %>% 
  rename_with(~gsub(., pattern = "X.", replacement = "")) %>% 
  rename(ASV = Query)
Taxtab_12S_tmp
```

### Merge datasets

```{r}
df_12S <- 
  Taxtab_12S_tmp %>%
  full_join(ASV_12S_tmp, by = "ASV") %>%
  pivot_longer(!1:12, names_to = "Library_ID", values_to = "Abundance") %>%
  full_join(Samptab_12S_tmp, by = "Library_ID")

df_12S

saveRDS(Taxtab_12S_tmp, "Data_export/Taxtab_12S.rds")
saveRDS(ASV_12S_tmp, "Data_export/ASV_12S.rds")
saveRDS(Samptab_12S_tmp, "Data_export/Samptab_12S.rds")
```

## Plot Sequencing Depth

```{r}
depth <-
  df_12S %>% 
  group_by(Library_ID) %>% 
  summarize(Abundance=sum(Abundance))
depth

depth %>%
  filter(is.na(Abundance) == FALSE) %>% 
  ggplot() +
  geom_bar(aes(Library_ID, Abundance), stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

# Data Export ###############

Upload clean version to remote repository.
Here Google Drive is used. Change according to preference.

```{r}
drive_auth()
source("Code/HelpScripts/Data_Export_Final.R")

upload_to_drive(repo = "Data_Novotny/AmpliconSeqAnalysis", datasets = c("18S"))
```


