---
title: "Inspect prepare and combine datasets"
---

```{r} 
library(lubridate)
#library(plotly)
library(tidyverse)
library(readxl)
library(googledrive)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

# 1. Prepare metadata

COI metadata

```{r}
Samptab_COI_all <-
  
  read_excel("ProcessedData/metadata_files/Library_metadata_all.xlsx", 
             sheet = "COI", col_types = c("text",
        "text", "date", "text", "text", "text", 
        "text", "date", "date", "numeric", 
        "text", "date", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "date", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "numeric", "numeric", "text"), na = "<NA>") %>% 
  select(!Quality_log)
Samptab_COI_all
write_csv2(Samptab_COI_all, "ProcessedData/metadata_files/sample_data_COI_all.csv")
```

18S Metadata
```{r}
qu39DNA_metadata <- read_excel(
   "ProcessedData/metadata_files/qu39DNA_metadata.xlsx", 
   col_types = c("date", "text", "text",
                 "text", "date", "date", "text", "numeric",
                 "text", "date", "text", "numeric",
                 "numeric", "numeric", "text", "text")) %>% 
  transmute(
    Library_ID = `Hakai ID`,
    Hakai_ID = `Hakai ID`,
    Sample_date = Date,
    Project_name = "QU39",
    Site_ID = `Site ID`,
    Line_out_depth = `Line Out Depth`,
    Sample_type = `Sample Type`,
    Time_collected = Collected,
    Time_preserved = Preserved,
    Sample_volume_ml = `Volume (ml)`,
    Sample_technician = `Lab Technician`,
    DNA_extraction_date = `DNA Extraction Date`,
    DNA_extraction_method = "Phenol-Clorophorm",
    DNA_volume_ul = `DNA Volume with TE Wash (ul)`,
    Qubit_DNA_Concentration_ngml = `Qubit DNA Concentration (ng/ml)`,
    Stock_DNA_Conentration_ngul =`Stock DNA Conentration (ng/ul)`,
    Extraction_staff = `Extraction Staff`,
    MiSeq_library = "Home18S",
    Library_staff = "Catherina Rodriguez"
  )

Library_metadata_Andreas <- read_excel("ProcessedData/metadata_files/Library_metadata_all.xlsx", 
     sheet = "18S", col_types = c("text", 
         "text", "date", "text", "text", "text", 
         "text", "date", "date", "numeric", 
         "text", "date", "text", "numeric", 
         "numeric", "numeric", "numeric", 
         "text", "text", "text", "text", "date", 
         "text", "text", "numeric", "numeric", 
         "text", "text", "text", "text", "numeric", 
         "numeric", "numeric"))
Library_metadata_Andreas

Samptab_18S_all <- bind_rows(Library_metadata_Andreas, qu39DNA_metadata)

Samptab_18S_all %>% 
  select(!Quality_log) %>% 
  write_csv2("ProcessedData/metadata_files/sample_data_18S_all.csv")

rm(Library_metadata_Andreas, qu39DNA_metadata)
```




# 2. General merging functions:

## completeTaxonomy()
```{r}

#' Fills unassigned taxonomic levels with useful information.
#'
#' This function assigns the higher taxonomic ranks to unassigned taxoomic levels, using the output of DADA2::assignTaxonomy.
#'
#' @param tax (Required) A list of two matrices. As returned from DADA2::assignTaxonomy(seqtab, database, outputBootstraps =  TRUE).
#' @param string (Optional, default="_x") A string. Will be attached at the end of the name comming from the higher taxonomic level.
#' @return A list of two matrices (modified tax object).
#' @examples
#' data("tax_16S")
#' tax_16S <- filterTaxonomy(tax_16S, minboot = 75)
#' tax_16S <- completeTaxonomy(tax_16S, string = "_x")
#'
#' @export

completeTaxonomy <- function(tax, string="_x") {
  
  TAX <- tax %>%
    as.data.frame() %>% 
    mutate(Annotation_level = 0) %>% 
    as.matrix()

  names <- colnames(TAX)
  for (row in 1:nrow(TAX)) {
    Count <- length(colnames(TAX))-1
    for (col in 1:(ncol(TAX)-1)) {
      if (is.na(TAX[row,col])) {
        Count <- Count - 1
        TAX[row,col] <- paste(TAX[row,(col-1)],string,sep="")
      }
    }
    TAX[row,ncol(TAX)] <- Count
  }
  return(TAX)
}
```

## merge_ASV_Tax()
```{r}

#' Merging ASV and Taxonomy table based on sequence
#' 
#' Not a generalized function. Only optimised for this analysis directory.

merge_ASV_Tax <- function(dir = "18S_QPKbulk_2017",
                          taxtab = "tax_tab_18S_MZGdb.RDS") {

  # Read ASV table, transpose and convert to tidy data frame format.
  ASV_tmp <-
    read.delim(paste("ProcessedData/",dir,"/sequence_table.merged.w_ASV_names.txt", sep = "")) %>% 
    column_to_rownames("row_names") %>% 
    t() %>%
    as.data.frame() %>% 
    rownames_to_column("ASV")
  
  # Read taxonomy table, fill NAs with readable information
  Taxtab_tmp <- readRDS(paste("ProcessedData/",dir,"/",taxtab, sep = ""))$tax %>%
    completeTaxonomy("@") %>% 
    as.data.frame() %>% 
    rownames_to_column("Sequence")
  
  # Read sequence ASV name file. Convert Taxtab sequences to ASV names,
  # and merge with ASV table.
  ASV_Tax_tmp <- read_delim(
    paste("ProcessedData/",dir,"/sequence_ASVname_mapping.txt", sep = ""),
    delim = "\t", escape_double = FALSE, 
    col_names = FALSE) %>% 
    transmute(ASV = X1, Sequence=X2) %>% 
    left_join(Taxtab_tmp, by = "Sequence") %>% 
    select(!Sequence) %>% 
    left_join(ASV_tmp, by = "ASV")
}

```

## merge_ASV_Tax_Samp()
```{r}
#' Merging ASV_Tax table with sample data
#' 
merge_ASV_Tax_Samp <- function(Run,
                               Taxtab,
                               Samptab ,
                               Group = NA) {
  
  Group <- ifelse(is.na(Group), Run, Group)
  
  ASV <- merge_ASV_Tax(Run, Taxtab) %>% 
    pivot_longer(15:length(.), names_to = "Library_ID", values_to = "Abundance")
  samples <- ASV %>%
      pull(Library_ID) %>% unique()

  Merged <- Samptab %>% 
    filter(MiSeq_library == Group,
           Library_ID %in% samples) %>% 
    full_join(ASV, by = "Library_ID") %>%
    filter(Library_ID != "Undetermined") %>% 
    mutate(Library_ID = paste(Library_ID, MiSeq_library, sep = "_" ))

}
```

## merge_COI()
```{r}
# COI Wrapper:
merge_COI <- function(Run,
                      Taxtab = "tax_tab_COI_MZGdb.RDS",
                      Samptab = Samptab_COI_all,
                      Group = NA) {
  merge_ASV_Tax_Samp(Run, Taxtab, Samptab, Group)
}
```

## merge_18S()
```{r}
# 18S Wrapper:
merge_18S <- function(Run,
                      Taxtab = "tax_tab_18S_MZGdb.RDS",
                      Samptab = Samptab_18S_all,
                      Group = NA) {
  merge_ASV_Tax_Samp(Run, Taxtab, Samptab, Group)
}



Samptab_18S_all
```


```{r}
seq_depth_plot <- function(data) {
  tmp <- data %>%
    mutate(Sample_Type = ifelse(
      is.na(Line_out_depth),
      "Control",
      "True_Sample")) %>% 
    group_by(Library_ID, Sample_Type, MiSeq_library) %>% 
    summarise(Library_Size = sum(Abundance)) %>% 
    arrange(Library_Size)
  
  tmp$Index <- seq(nrow(tmp))
  tmp %>% 
    ggplot() +
    geom_point(aes(Index, Library_Size, colour = Sample_Type))
}
```


# 3. Merge COI libraries
```{r}
All_COI_data <- bind_rows(
  merge_COI("COI_QPKbulk_2017"),
  merge_COI("COI_QU39-2017"),
  merge_COI("COI_QU39-2018"),
  merge_COI("COI_QU39-2019"),
  merge_COI("COI_Zoopsprint2022"))

p1 <- seq_depth_plot(All_COI_data)
plotly::ggplotly(p1) 
  
p2 <- All_COI_data %>% 
  filter(Kingdom == "Animalia") %>% 
  seq_depth_plot()
plotly::ggplotly(p2)

```


# 4. Merge 18S

```{r}
All_18S_data <- bind_rows(
  merge_18S("18S_QPKbulk_2017"),
  merge_18S("18S_QU39_1"),
  merge_18S("18S_QU39_2"),
  merge_18S("18S_QU39_3"),
  merge_18S("18S_QU39_4"),
  merge_18S("18S_QU39_5"),
  merge_18S("18S_QU39_6")
  )

p1 <- All_18S_data %>%
  filter(is.na(Hakai_ID)==FALSE) %>% 
  seq_depth_plot()
plotly::ggplotly(p1)

```




# Data Export ###############

Upload clean version to remote repository.
Here Google Drive is used. Change according to preference.

```{r}
drive_auth()
source("Code/HelpScripts/Data_Export_Final.R")

upload_to_drive(repo = "Data_Novotny/AmpliconSeqAnalysis", datasets = c("18S"))
```